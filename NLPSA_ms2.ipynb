{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b92ba51",
   "metadata": {},
   "source": [
    "#  Data extraction from small dataset\n",
    "Load in the small_corpus .csv file you created in the previous milestone.\n",
    "\n",
    "Tokenize the sentences and words of the reviews with the tokenize module of NLTK.\n",
    "\n",
    "Keep in mind that word_tokenize and sent_tokenize functions of the nltk.tokenize module should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec6844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "#smalldf = pd.read_csv('DATASET/vgBalanced.csv', names = ['rating', 'review'])\n",
    "smalldf = pd.read_csv('DATASET/vg100k.csv', names = ['rating', 'review'])\n",
    "smalldf['review'] = smalldf['review'].str.lower()\n",
    "smalldf['sents'] = smalldf['review'].apply(sent_tokenize)\n",
    "smalldf['n_sentences'] = smalldf['sents'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bfdbed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating                                                       3.0\n",
       "review         never wrote a review about the 360 until i sta...\n",
       "sents          [never wrote a review about the 360 until i st...\n",
       "n_sentences                                                    5\n",
       "Name: 29, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldf.loc[29].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a851a0b",
   "metadata": {},
   "source": [
    "# Classification with opinion lexicon\n",
    "\n",
    "Classify each review in a scale of –1 to +1. The higher the score is, the more positive the review is.\n",
    "\n",
    "It is recommended to score the reviews in two steps. First score the sentences of the reviews from –1 to 1 based on the sum of the positive and negative words they include. Then count the sentiment score of the reviews, which you preliminary sliced into sentences.\n",
    "Don’t forget that NLTK opinion lexicon neither contains uppercase words, nor punctuation marks.\n",
    "\n",
    "--------------------------\n",
    "First scoring each sentence based on the word score.  One score per sentence is kept in the dataframe.  The score is not normalized since there is no way to normalize at first.  \n",
    "\n",
    "Steps:  \n",
    "1- For each review, score the sentences based on +1 -1.  A sentence may get a score of -6, +5 and is not limited in range\n",
    "2- Once all the sentences have been scored based on the number of keywords, \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370f8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence(sentence):\n",
    "    score=0\n",
    "    for word in sentence:\n",
    "        if word in ndict:\n",
    "            score-=1\n",
    "        if word in pdict:\n",
    "            score+=1        \n",
    "    return score\n",
    "\n",
    "def score_review(sentences):\n",
    "    n_sentence = len(sentences)\n",
    "    if n_sentence==0:\n",
    "        return 0\n",
    "    total_score=0\n",
    "    s_index=0\n",
    "    #sscores=[]\n",
    "    for sentence in sentences :\n",
    "        total_score = score_sentence(word_tokenize(sentence)) + total_score\n",
    "        #sscores.append(score_sentence(word_tokenize(sentence))) \n",
    "    return(total_score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf74ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "ndict = dict.fromkeys(opinion_lexicon.negative())\n",
    "pdict = dict.fromkeys(opinion_lexicon.positive())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b07310a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myscore = score_review(smalldf['sents'].loc[29])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb81eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 74.55047564 to process\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "stime =time.process_time()\n",
    "smalldf['score'] = smalldf['sents'].apply(score_review)\n",
    "etime = time.process_time()\n",
    "print(f\"It took {etime-stime} to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e07d3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>7.599535</td>\n",
       "      <td>-0.998008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>10.610018</td>\n",
       "      <td>0.146015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>10.624373</td>\n",
       "      <td>1.985144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>9.949114</td>\n",
       "      <td>3.718030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>5.546167</td>\n",
       "      <td>3.122315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_sentences     score\n",
       "rating                       \n",
       "1.0        7.599535 -0.998008\n",
       "2.0       10.610018  0.146015\n",
       "3.0       10.624373  1.985144\n",
       "4.0        9.949114  3.718030\n",
       "5.0        5.546167  3.122315"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldf.groupby('rating').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
